{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Dec 11 02:33:01 2017\n",
    "@author: rmisra\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pylmnn.lmnn import LargeMarginNearestNeighbor as LMNN\n",
    "from pylmnn.plots import plot_comparison\n",
    "from collections import defaultdict\n",
    "\n",
    "def parseData(file):\n",
    "    for l in open(file,'r'):\n",
    "        yield json.loads(l)\n",
    "        \n",
    "def remove_punctuation(text):\n",
    "    return ''.join([c.lower() for c in text if c not in set(string.punctuation)])\n",
    "\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of 1-LV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Proposed in https://dl.acm.org/citation.cfm?id=3109891"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = list(parseData('./renttherunway_final_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bra size': '40',\n",
       " 'category': 'new',\n",
       " 'cup size': 'd',\n",
       " 'fit': 'small',\n",
       " 'height': '5ft 6in',\n",
       " 'hips': '49.0',\n",
       " 'item_id': '123373',\n",
       " 'length': 'just right',\n",
       " 'quality': 4,\n",
       " 'size': 24,\n",
       " 'user_id': '205796',\n",
       " 'user_name': 'micorson'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66232, 8279, 8279)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(1)\n",
    "random.shuffle(data)\n",
    "\n",
    "train_data = data[:int(0.8*len(data))]\n",
    "val_data = data[int(0.8*len(data)):int(0.9*len(data))]\n",
    "test_data = data[int(0.9*len(data)):]\n",
    "\n",
    "len(train_data), len(val_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index user and items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     6
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_data = {}\n",
    "item_index = {}\n",
    "user_index = {}\n",
    "user_data = {}\n",
    "u_index = 0\n",
    "i_index = 0\n",
    "for r in train_data:\n",
    "    if r['item_id'] + '|' + str(r['size']) not in item_data:\n",
    "        item_data[r['item_id'] + '|' + str(r['size'])] = [r]\n",
    "        item_index[r['item_id'] + '|' + str(r['size'])] = i_index\n",
    "        i_index += 1\n",
    "    else:\n",
    "        item_data[r['item_id'] + '|' + str(r['size'])].append(r)\n",
    "        \n",
    "    if r['user_id'] not in user_data:\n",
    "        user_data[r['user_id']] = [r]\n",
    "        user_index[r['user_id']] = u_index\n",
    "        u_index += 1\n",
    "    else:\n",
    "        user_data[r['user_id']].append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90510, 90510, 28938, 28938)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_data), len(user_index), len(item_data), len(item_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize items' true sizes with respective catalog sizes and users' true sizes randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_size_item = np.zeros(len(item_data))\n",
    "true_size_cust = np.zeros(len(user_data))\n",
    "w = 1; b_1 = -1; b_2 = 1; lamda = 2\n",
    "\n",
    "for item in item_data:\n",
    "    true_size_item[item_index[item]] = int(item.split('|')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     1,
     22,
     57,
     60,
     72,
     84,
     98,
     101,
     130,
     162
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 110235.080176\n",
      "5 97592.6381926\n",
      "10 85552.0624424\n",
      "15 79780.1737845\n",
      "20 72622.7751206\n",
      "25 66627.0028311\n",
      "30 62503.85468\n",
      "35 59026.3071246\n",
      "40 55979.6720675\n",
      "45 54228.2433566\n",
      "50 51727.1679254\n",
      "55 49539.4826269\n",
      "60 47560.3890943\n",
      "65 46017.8013146\n",
      "70 44426.1127107\n",
      "75 43615.1951736\n",
      "80 42333.6031368\n",
      "85 41443.5373367\n",
      "90 40694.9372432\n",
      "95 39796.9039791\n",
      "100 39387.5833475\n",
      "105 38829.7321627\n",
      "110 38143.4384831\n",
      "115 37594.6932793\n",
      "120 37117.5729794\n",
      "125 36664.4669744\n",
      "130 36271.1902006\n",
      "135 35652.194969\n",
      "140 35570.2466254\n",
      "145 35116.3961246\n",
      "150 35379.8238706\n",
      "155 35104.0334593\n",
      "160 35045.2903899\n",
      "165 34673.2352997\n",
      "170 34518.6455033\n",
      "175 34403.4107289\n",
      "180 34177.4092512\n",
      "185 34384.1654521\n",
      "190 34237.3282408\n",
      "195 34020.6336939\n",
      "200 33599.5544234\n",
      "205 33651.9374839\n",
      "210 33392.3265607\n",
      "215 33237.2078762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "def calc_auc():\n",
    "    train_features = []\n",
    "    train_labels = []\n",
    "    for r in train_data:\n",
    "        fe = []\n",
    "        fe.append(true_size_cust[user_index[r['user_id']]])\n",
    "        fe.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])\n",
    "        train_features.append(fe)\n",
    "\n",
    "        if 'small' in r['fit']:\n",
    "            train_labels.append(0)\n",
    "        elif 'fit' in r['fit']:\n",
    "            train_labels.append(1)\n",
    "        elif 'large' in r['fit']:\n",
    "            train_labels.append(2)\n",
    "\n",
    "    c = 1\n",
    "    clf_1LV = LogisticRegression(fit_intercept=True, multi_class='ovr', C=c)\n",
    "    clf_1LV.fit(train_features, train_labels)\n",
    "\n",
    "    test_features = []; test_labels = []; test_labels_auc = []\n",
    "    for r in test_data:\n",
    "        fe = []\n",
    "        try:\n",
    "            fe.append(true_size_cust[user_index[r['user_id']]])\n",
    "        except KeyError:\n",
    "            fe.append(np.mean(true_size_cust))\n",
    "        try:\n",
    "            fe.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])\n",
    "        except KeyError:\n",
    "            fe.append(np.mean(true_size_item))\n",
    "\n",
    "        test_features.append(fe)\n",
    "        label = [0, 0, 0]\n",
    "        if 'small' in r['fit']:\n",
    "            test_labels.append(0)\n",
    "            label[0] = 1\n",
    "        elif 'fit' in r['fit']:\n",
    "            test_labels.append(1)\n",
    "            label[1] = 1\n",
    "        elif 'large' in r['fit']:\n",
    "            test_labels.append(2)\n",
    "            label[2] = 1\n",
    "        test_labels_auc.append(label)\n",
    "\n",
    "    test_labels_auc = np.array(test_labels_auc)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "\n",
    "    pred = clf_1LV.predict_proba(test_features)\n",
    "    AUC = []\n",
    "    for i in range(3):\n",
    "        AUC.append(roc_auc_score(test_labels_auc[:,i], pred[:,i], average='weighted'))\n",
    "    print('Average AUC', np.mean(AUC), AUC)\n",
    "    \n",
    "def f(s,t):\n",
    "    return w*(s-t)\n",
    "\n",
    "def cal_loss_user(user, cust_size):\n",
    "    loss = 0\n",
    "    for r in user_data[user]:\n",
    "        if 'small' in r['fit']:\n",
    "            loss += max(0, 1 - f(cust_size, true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]) + b_2)\n",
    "        elif 'fit' in r['fit']:\n",
    "            loss += max(0, 1 + f(cust_size, true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]) - b_2)\n",
    "            loss += max(0, 1 - f(cust_size, true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]) + b_1)\n",
    "        elif 'large' in r['fit']:\n",
    "            loss += max(0, 1 + f(cust_size, true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]) - b_1)\n",
    "    return loss\n",
    "            \n",
    "def cal_loss_item(item, product_size):\n",
    "    loss = 0\n",
    "    for r in item_data[item]:\n",
    "        if 'small' in r['fit']:\n",
    "            loss += max(0, 1 - f(true_size_cust[user_index[r['user_id']]], product_size) + b_2)\n",
    "        elif 'fit' in r['fit']:\n",
    "            loss += max(0, 1 + f(true_size_cust[user_index[r['user_id']]], product_size) - b_2)\n",
    "            loss += max(0, 1 - f(true_size_cust[user_index[r['user_id']]], product_size) + b_1)\n",
    "        elif 'large' in r['fit']:\n",
    "            loss += max(0, 1 + f(true_size_cust[user_index[r['user_id']]], product_size) - b_1)\n",
    "    return loss\n",
    "\n",
    "def total_loss():\n",
    "    loss = 0\n",
    "    for item in item_data:\n",
    "        for r in item_data[item]:\n",
    "            product_size = true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]\n",
    "            if 'small' in r['fit']:\n",
    "                loss += max(0, 1 - f(true_size_cust[user_index[r['user_id']]], product_size) + b_2)\n",
    "            elif 'fit' in r['fit']:\n",
    "                loss += max(0, 1 + f(true_size_cust[user_index[r['user_id']]], product_size) - b_2)\n",
    "                loss += max(0, 1 - f(true_size_cust[user_index[r['user_id']]], product_size) + b_1)\n",
    "            elif 'large' in r['fit']:\n",
    "                loss += max(0, 1 + f(true_size_cust[user_index[r['user_id']]], product_size) - b_1)\n",
    "    return loss\n",
    "\n",
    "for iterr in range(0,220):\n",
    "    \n",
    "    ## Phase 1\n",
    "    for user in user_data:\n",
    "        candidate_sizes = []\n",
    "        for r in user_data[user]:\n",
    "            if 'small' in r['fit']:\n",
    "                candidate_sizes.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]] + ((b_2+1)/w))\n",
    "            elif 'fit' in r['fit']:\n",
    "                candidate_sizes.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]] + ((b_1+1)/w))\n",
    "                candidate_sizes.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]] + ((b_2-1)/w))\n",
    "            elif 'large' in r['fit']:\n",
    "                candidate_sizes.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]] + ((b_1-1)/w))\n",
    "\n",
    "        flag = 0\n",
    "        candidate_sizes = list(set(candidate_sizes))\n",
    "        candidate_sizes = sorted(candidate_sizes)\n",
    "\n",
    "        if len(candidate_sizes) == 1:\n",
    "            true_size_cust[user_index[user]] = candidate_sizes[0]\n",
    "        else:\n",
    "            for s in range(1, len(candidate_sizes)):\n",
    "                slope = (cal_loss_user(user, candidate_sizes[s]) - cal_loss_user(user, candidate_sizes[s-1]))/(candidate_sizes[s] - candidate_sizes[s-1])\n",
    "                if slope>=0:\n",
    "                    flag=1\n",
    "                    true_size_cust[user_index[user]] = candidate_sizes[s-1]\n",
    "                    break\n",
    "\n",
    "            if flag==0:\n",
    "                true_size_cust[user_index[user]] = candidate_sizes[-1]\n",
    "\n",
    "    ## Phase 2\n",
    "    for item in item_data:\n",
    "        candidate_sizes = []\n",
    "        for r in item_data[item]:\n",
    "            if 'small' in r['fit']:\n",
    "                candidate_sizes.append(true_size_cust[user_index[r['user_id']]] - ((b_2+1)/w))\n",
    "            elif 'fit' in r['fit']:\n",
    "                candidate_sizes.append(true_size_cust[user_index[r['user_id']]] - ((b_1+1)/w))\n",
    "                candidate_sizes.append(true_size_cust[user_index[r['user_id']]] - ((b_2-1)/w))\n",
    "            elif 'large' in r['fit']:\n",
    "                candidate_sizes.append(true_size_cust[user_index[r['user_id']]] - ((b_1-1)/w))\n",
    "\n",
    "        flag = 0\n",
    "        candidate_sizes = list(set(candidate_sizes))\n",
    "        candidate_sizes = sorted(candidate_sizes)\n",
    "        if len(candidate_sizes) == 1:\n",
    "            true_size_item[item_index[item]] = candidate_sizes[0]\n",
    "        else:\n",
    "            for s in range(1, len(candidate_sizes)):\n",
    "                slope = (cal_loss_item(item, candidate_sizes[s]) - cal_loss_item(item, candidate_sizes[s-1]))/(candidate_sizes[s] - candidate_sizes[s-1])\n",
    "                if slope>=0:\n",
    "                    flag=1\n",
    "                    true_size_item[item_index[item]] = candidate_sizes[s-1]\n",
    "                    break\n",
    "\n",
    "            if flag==0:\n",
    "                true_size_item[item_index[item]] = candidate_sizes[-1]\n",
    "\n",
    "    ## Phase 3\n",
    "    learning_rate = 0.0000005/np.sqrt(iterr+1)\n",
    "    grad_w = 0\n",
    "    grad_b1 = 0\n",
    "    grad_b2 = 0\n",
    "    for r in train_data:\n",
    "        s = true_size_cust[user_index[r['user_id']]]\n",
    "        t = true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]\n",
    "\n",
    "        if 'small' in r['fit']:\n",
    "            A = 1 - f(s, t) + b_2\n",
    "            if A>0:\n",
    "                grad_w += -1*(s - t)\n",
    "                grad_b2 += 1\n",
    "        elif 'fit' in r['fit']:\n",
    "            B = 1 + f(s, t) - b_2\n",
    "            C = 1 - f(s, t) + b_1\n",
    "            if B>0:\n",
    "                grad_w += (s - t)\n",
    "                grad_b2 += -1\n",
    "            if C>0:\n",
    "                grad_w += -1*(s - t)\n",
    "                grad_b1 += 1\n",
    "        elif 'large' in r['fit']:\n",
    "            D = 1 + f(s, t) - b_1\n",
    "            if D>0:\n",
    "                grad_w += (s - t)\n",
    "                grad_b1 += -1\n",
    "\n",
    "    w -= learning_rate*(grad_w + 2*lamda*w)\n",
    "    b_1 -= learning_rate*(grad_b1 + 2*lamda*b_1)\n",
    "    b_2 -= learning_rate*(grad_b2 + 2*lamda*b_2)\n",
    "    if iterr%5 == 0:\n",
    "        print(iterr, total_loss())\n",
    "        calc_auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the above learned features in a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     5,
     23,
     37,
     40,
     52
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC 0.593345133084 [0.60000002299011235, 0.55929955183803415, 0.62073582442255582]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "train_features = []; train_labels = []\n",
    "for r in train_data:\n",
    "    fe = []\n",
    "    fe.append(true_size_cust[user_index[r['user_id']]])\n",
    "    fe.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])\n",
    "    train_features.append(fe)\n",
    "\n",
    "    if 'small' in r['fit']:\n",
    "        train_labels.append(0)\n",
    "    elif 'fit' in r['fit']:\n",
    "        train_labels.append(1)\n",
    "    elif 'large' in r['fit']:\n",
    "        train_labels.append(2)\n",
    "\n",
    "c = 1\n",
    "clf_1LV = LogisticRegression(fit_intercept=True, multi_class='ovr', C=c)\n",
    "clf_1LV.fit(train_features, train_labels)\n",
    "\n",
    "test_features = []; test_labels = []; test_labels_auc = []\n",
    "for r in val_data:\n",
    "    fe = []\n",
    "    try:\n",
    "        u = user_index[r['user_id']]\n",
    "        fe.append(true_size_cust[u])\n",
    "    except KeyError:\n",
    "        fe.append(np.mean(true_size_cust))\n",
    "    try:\n",
    "        fe.append(true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])\n",
    "    except KeyError:\n",
    "        fe.append(np.mean(true_size_item))\n",
    "\n",
    "    test_features.append(fe)\n",
    "    label = [0, 0, 0]\n",
    "    if 'small' in r['fit']:\n",
    "        test_labels.append(0)\n",
    "        label[0] = 1\n",
    "    elif 'fit' in r['fit']:\n",
    "        test_labels.append(1)\n",
    "        label[1] = 1\n",
    "    elif 'large' in r['fit']:\n",
    "        test_labels.append(2)\n",
    "        label[2] = 1\n",
    "    test_labels_auc.append(label)\n",
    "\n",
    "test_labels_auc = np.array(test_labels_auc)\n",
    "\n",
    "pred = clf_1LV.predict_proba(test_features)\n",
    "AUC = []\n",
    "for i in range(3):\n",
    "    AUC.append(roc_auc_score(test_labels_auc[:,i], pred[:,i], average='weighted'))\n",
    "print('Average AUC', np.mean(AUC), AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of K-LF-ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create users' and items' (parent and child) indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     11
    ],
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105571, 105571, 30815, 30815, 5850)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_data = {}; user_data = {}\n",
    "item_index = {}; user_index = {}; p_item_index = {} ## p_ is for parent \n",
    "u_index = 0; i_index = 0; p_i_index = 0\n",
    "sizes = {}\n",
    "s_index = 0\n",
    "\n",
    "for r in data:\n",
    "    if r['size'] not in sizes:\n",
    "        sizes[r['size']] = s_index\n",
    "        s_index += 1\n",
    "\n",
    "    if r['item_id'] + '|' + str(r['size']) not in item_data:\n",
    "        item_data[r['item_id'] + '|' + str(r['size'])] = [r]\n",
    "        item_index[r['item_id'] + '|' + str(r['size'])] = i_index\n",
    "        i_index += 1\n",
    "    else:\n",
    "        item_data[r['item_id'] + '|' + str(r['size'])].append(r)\n",
    "        \n",
    "    if r['item_id'] not in p_item_index:\n",
    "        p_item_index[r['item_id']] = p_i_index\n",
    "        p_i_index += 1\n",
    "        \n",
    "    if r['user_id'] not in user_data:\n",
    "        user_data[r['user_id']] = [r]\n",
    "        user_index[r['user_id']] = u_index\n",
    "        u_index += 1\n",
    "    else:\n",
    "        user_data[r['user_id']].append(r)\n",
    "len(user_data), len(user_index), len(item_data), len(item_index), len(p_item_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For monotonicity constraints, for each product, record smaller and larger sized products, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {
    "code_folding": [
     2,
     8,
     15
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_sizes = {}; product_sizes_rev = {}\n",
    "\n",
    "for r in data:\n",
    "    if r['item_id'] not in product_sizes:\n",
    "        product_sizes[r['item_id']] = [r['size']]\n",
    "    else:\n",
    "        product_sizes[r['item_id']].append(r['size'])\n",
    "        \n",
    "for k in product_sizes:\n",
    "    product_sizes[k] = list(sorted(set(product_sizes[k])))\n",
    "    product_sizes_rev[k] = list(sorted(set(product_sizes[k]), reverse=True))\n",
    "    \n",
    "product_smaller = {}\n",
    "product_larger = {}\n",
    "\n",
    "for k in product_sizes:\n",
    "    for i in range(len(product_sizes[k])):\n",
    "        if len(product_sizes[k]) == 1:\n",
    "            product_smaller[item_index[k + '|' + str(product_sizes[k][i])]] = -1\n",
    "            product_larger[item_index[k + '|' + str(product_sizes[k][i])]] = -1\n",
    "        elif i == 0:\n",
    "            product_smaller[item_index[k + '|' + str(product_sizes[k][i])]] = -1\n",
    "            product_larger[item_index[k + '|' + str(product_sizes[k][i])]] = item_index[k + '|' + str(product_sizes[k][i+1])]\n",
    "        elif i == len(product_sizes[k]) - 1:\n",
    "            product_smaller[item_index[k + '|' + str(product_sizes[k][i])]] = item_index[k + '|' + str(product_sizes[k][i-1])]\n",
    "            product_larger[item_index[k + '|' + str(product_sizes[k][i])]] = -1\n",
    "        else:\n",
    "            product_smaller[item_index[k + '|' + str(product_sizes[k][i])]] = item_index[k + '|' + str(product_sizes[k][i-1])]\n",
    "            product_larger[item_index[k + '|' + str(product_sizes[k][i])]] = item_index[k + '|' + str(product_sizes[k][i+1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompose fit semantics using latent factor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2384,
   "metadata": {
    "code_folding": [
     10
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f(a,b_i,b_u,s,t):\n",
    "    return np.dot(w, np.concatenate(([a, b_u, b_i], np.multiply(s, t))))\n",
    "\n",
    "K = 10; learning_rate = 0.000005; alpha = 1; \n",
    "true_size_item = np.random.normal(size = (len(item_index), K))*0.1\n",
    "true_size_cust = np.random.normal(size = (len(user_index), K), loc=1, scale=0.1)\n",
    "bias_i = np.random.normal(size = (len(item_index)))*0.1\n",
    "bias_u = np.random.normal(size = (len(user_index)))*0.1\n",
    "b_1 = -5; b_2 = 5; lamda = 2; w = np.ones(K+3)\n",
    "\n",
    "for k in product_sizes:\n",
    "    start = len(product_sizes[k])\n",
    "    for size in product_sizes[k]:\n",
    "        true_size_item[item_index[k + '|' + str(size)]] = np.random.normal(size=(1,K), loc=start, scale=0.1)\n",
    "        start -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2385,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_auc():\n",
    "    train_features = []; train_labels = []\n",
    "    for r in train_data:\n",
    "        fe = []\n",
    "        fe.append(w[1]*bias_u[user_index[r['user_id']]])\n",
    "        fe.append(w[2]*bias_i[p_item_index[r['item_id']]])\n",
    "        fe.extend(np.multiply(w[3:], np.multiply(true_size_cust[user_index[r['user_id']]], true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])))\n",
    "\n",
    "        train_features.append(fe)\n",
    "\n",
    "        if 'small' in r['fit']:\n",
    "            train_labels.append(1)\n",
    "        elif 'fit' in r['fit']:\n",
    "            train_labels.append(2)\n",
    "        elif 'large' in r['fit']:\n",
    "            train_labels.append(3)\n",
    "\n",
    "    clf = LogisticRegression(fit_intercept=True, multi_class='ovr')\n",
    "    clf.fit(train_features, train_labels)\n",
    "\n",
    "    test_features = []; test_labels = []; test_labels_auc = []\n",
    "    for r in test_data:\n",
    "        fe = []\n",
    "        flag = 0\n",
    "        fe.append(w[1]*bias_u[user_index[r['user_id']]])\n",
    "        fe.append(w[2]*bias_i[p_item_index[r['item_id']]])\n",
    "        fe.extend(np.multiply(w[3:], np.multiply(true_size_cust[user_index[r['user_id']]], true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])))\n",
    "\n",
    "        test_features.append(fe)\n",
    "        label = [0, 0, 0]\n",
    "        if 'small' in r['fit']:\n",
    "            test_labels.append(1)\n",
    "            label[0] = 1\n",
    "        elif 'fit' in r['fit']:\n",
    "            test_labels.append(2)\n",
    "            label[1] = 1\n",
    "        elif 'large' in r['fit']:\n",
    "            test_labels.append(3)\n",
    "            label[2] = 1\n",
    "        test_labels_auc.append(label)\n",
    "\n",
    "    test_labels_auc = np.array(test_labels_auc)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    pred = clf.predict_proba(test_features)\n",
    "    AUC = []\n",
    "    for i in range(3):\n",
    "        AUC.append(roc_auc_score(test_labels_auc[:,i], pred[:,i], average='weighted'))\n",
    "    print('Average AUC', np.mean(AUC), AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2386,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_metric_auc():\n",
    "    U = true_size_cust; V = true_size_item\n",
    "    def prepare_features(data):\n",
    "        X = []\n",
    "        Y = []\n",
    "        Y_auc = []\n",
    "        item_l = []\n",
    "        item_n = []\n",
    "        items = {}\n",
    "        item_count = defaultdict(int)\n",
    "        item_small = defaultdict(int)\n",
    "        frac_small = []\n",
    "        for r in data:\n",
    "            fe = []\n",
    "            fe.append(w[1]*bias_u[user_index[r['user_id']]])\n",
    "            fe.append(w[2]*bias_i[p_item_index[r['item_id']]])\n",
    "            fe.extend(np.multiply(w[3:], np.multiply(true_size_cust[user_index[r['user_id']]], true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]])))\n",
    "            X.append(fe)\n",
    "            item_l.append(np.multiply(w[3:],V[item_index[r['item_id'] + '|' + str(r['size'])]]))\n",
    "            item_n.append(str(r['category']))\n",
    "            items[r['item_id'] + '|' + str(r['size'])] = 1\n",
    "            if 'small' in r['fit']:\n",
    "                Y.append(0)\n",
    "                Y_auc.append([1,0,0])\n",
    "            elif 'fit' in r['fit']:\n",
    "                Y.append(1)\n",
    "                Y_auc.append([0,1,0])\n",
    "            else:\n",
    "                Y.append(2)\n",
    "                Y_auc.append([0,0,1])\n",
    "\n",
    "        for r in train_data:\n",
    "            if (r['item_id'] + '|' + str(r['size'])) in items:\n",
    "                item_count[r['item_id'] + '|' + str(r['size'])] += 1\n",
    "                if 'small' in r['fit']:\n",
    "                    item_small[r['item_id'] + '|' + str(r['size'])] += 1\n",
    "        for k in item_count:\n",
    "            item_small[k] = item_small[k]/item_count[k]\n",
    "\n",
    "        for r in data:\n",
    "            frac_small.append(item_small[r['item_id'] + '|' + str(r['size'])])\n",
    "\n",
    "        return np.array(X),np.array(Y), np.array(Y_auc), np.array(item_l), item_n, frac_small\n",
    "    \n",
    "    def select_prototype(data):\n",
    "        chosen_data = []\n",
    "        X_small,_,_,_,_,_ = prepare_features(data)\n",
    "        small_mean = np.mean(X_small, axis = 0)\n",
    "        dist = []\n",
    "        for i in range(len(data)):\n",
    "            dist.append((i, sum([(X_small[i][j]-small_mean[j])**2 for j in range(len(small_mean))])))\n",
    "        if 'fit' in data[0]['fit']:\n",
    "            small_temp = sorted(dist, key=operator.itemgetter(1))[1300:]\n",
    "            interval = int(len(data)/5000)\n",
    "            for i in range(100):\n",
    "                chosen_data.append(data[small_temp[int(i*interval)][0]])\n",
    "                interval += 4\n",
    "        elif 'small' in data[0]['fit']:\n",
    "            small_temp = sorted(dist, key=operator.itemgetter(1))[1200:]\n",
    "            interval = int(len(data)/1000)\n",
    "            for i in range(100):\n",
    "                chosen_data.append(data[small_temp[int(i*interval)][0]])\n",
    "                interval += 1.15\n",
    "        else:\n",
    "            small_temp = sorted(dist, key=operator.itemgetter(1))[1200:]\n",
    "            interval = int(len(data)/500)\n",
    "            for i in range(100):\n",
    "                chosen_data.append(data[small_temp[int(i*interval)][0]])\n",
    "                interval += 0.5\n",
    "\n",
    "        return chosen_data\n",
    "\n",
    "    small = []; true = []; large= []\n",
    "    for r in range(len(train_data)):\n",
    "        if 'small' in train_data[r]['fit']:\n",
    "            small.append(train_data[r])\n",
    "        elif 'fit' in train_data[r]['fit']:\n",
    "            true.append(train_data[r])\n",
    "        else:\n",
    "            large.append(train_data[r])\n",
    "\n",
    "    random.shuffle(small); random.shuffle(true); random.shuffle(large)\n",
    "    data_training = [];\n",
    "    data_training.extend(select_prototype(small)); data_training.extend(select_prototype(true)); data_training.extend(select_prototype(large))\n",
    "\n",
    "    random.shuffle(data_training)\n",
    "    X_train, Y_train, Y_train_auc, item_l, item_n, frac_small = prepare_features(data_training)\n",
    "    X_test, Y_test, Y_test_auc, _, _, _ = prepare_features(test_data)\n",
    "\n",
    "    clf_kLF = LMNN(n_neighbors=53, max_iter=50, n_features_out=X_train.shape[1], verbose=0)\n",
    "    clf_kLF = clf_kLF.fit(X_train, Y_train)\n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    pred = clf_kLF.predict_proba(X_test); AUC = []\n",
    "    for i in range(3):\n",
    "        AUC.append(roc_auc_score(Y_test_auc[:,i], pred[:,i], average='weighted'))\n",
    "    print('Average AUC', np.mean(AUC), AUC)\n",
    "    return np.mean(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2387,
   "metadata": {
    "code_folding": [
     0,
     18
    ],
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 64581877.5164 -4.80247 6.13749 [-0.33506     1.00051776  0.99785147 -7.75771491]\n",
      "Average AUC 0.548822902839 [0.58857261257394922, 0.55221216346876556, 0.50568393247391275]\n",
      "Average AUC 0.544669338211 [0.58828627068765116, 0.54247864455208217, 0.5032430993934226]\n",
      "5 894719.42936 -6.58551963494 6.19361161792 [ 1.39176243  0.99833965  0.94317595  0.30117315]\n",
      "Average AUC 0.553728248223 [0.56158067483503427, 0.53326959425427201, 0.56633447557836003]\n",
      "Average AUC 0.528741099299 [0.53766261718822206, 0.52355617989303715, 0.52500450081590222]\n",
      "10 363467.264195 -6.47884465066 6.10710263495 [ 1.37152914  0.99919527  0.94205121 -0.03401847]\n",
      "Average AUC 0.575466022509 [0.57748676432396262, 0.52968047540347285, 0.61923082779821403]\n",
      "Average AUC 0.567708942474 [0.56208943512825016, 0.52657577170882119, 0.61446162058508635]\n",
      "15 349311.294409 -6.21378737819 5.83133365679 [ 1.38218719  1.00137381  0.97461683 -0.03618816]\n",
      "Average AUC 0.592438480971 [0.59947592546464423, 0.52984261583285019, 0.64799690161615109]\n",
      "Average AUC 0.588929174532 [0.59632737676573822, 0.52542196738043223, 0.64503817944859421]\n",
      "20 335406.499016 -5.98667929473 5.5950475005 [ 1.3913193   1.00408706  1.01768647 -0.02050286]\n",
      "Average AUC 0.604985949944 [0.6206360842651345, 0.53139280244117204, 0.6629289631265225]\n",
      "Average AUC 0.60520550674 [0.61897605377006182, 0.53524398092957093, 0.66139648552074171]\n",
      "25 322475.828289 -5.78477540944 5.38498411453 [ 1.39943794  1.00724889  1.06994706 -0.00629873]\n",
      "Average AUC 0.612907147867 [0.63623040459823144, 0.53174009847617676, 0.6707509405251425]\n",
      "Average AUC 0.617420543844 [0.63852446924543382, 0.54052617140986603, 0.67321099087552883]\n",
      "30 310167.428626 -5.60118292519 5.19397214452 [ 1.40682026  1.0108039   1.13074264  0.00644947]\n",
      "Average AUC 0.617040772455 [0.64750580835742599, 0.53044785547603812, 0.67316865353033917]\n",
      "Average AUC 0.625094222671 [0.65259524512466638, 0.54215233507882965, 0.68053508780922467]\n",
      "35 298308.064625 -5.43167391212 5.01798805809 [ 1.41326103  1.01466547  1.19905643  0.01749521]\n",
      "Average AUC 0.619684465249 [0.65511891165463976, 0.52996605520916729, 0.67396842888222275]\n",
      "Average AUC 0.631328248577 [0.66339601224997247, 0.54385678804848947, 0.68673194543338489]\n",
      "40 287225.124295 -5.27343342662 4.85898116819 [ 1.41399541  1.01855299  1.26541314  0.01863931]\n",
      "Average AUC 0.62182178746 [0.66283996479999407, 0.52696813307766455, 0.67565726450271391]\n",
      "Average AUC 0.63544589513 [0.67122623588994279, 0.54436734517970409, 0.69074410432084909]\n",
      "45 276299.6251 -5.12448127916 4.71011193616 [ 1.41388234  1.02264832  1.3387663   0.01861444]\n",
      "Average AUC 0.623273226097 [0.66875360728254418, 0.52378227788539022, 0.67728379312397635]\n",
      "Average AUC 0.640080981065 [0.67826850930721161, 0.54524804230918511, 0.69672639157943661]\n",
      "50 266517.11042 -4.98725328326 4.57152681961 [ 1.4152109   1.02672702  1.39834951  0.02183005]\n",
      "Average AUC 0.627059312901 [0.67423744466818114, 0.52364485784444992, 0.68329563618995304]\n",
      "Average AUC 0.642906884093 [0.68289985980216195, 0.54603462244838175, 0.69978617002838495]\n",
      "55 256856.506713 -4.85662156122 4.44099259047 [ 1.41508619  1.031028    1.46240209  0.02346408]\n",
      "Average AUC 0.630013679575 [0.67868216232858269, 0.52312743835830888, 0.68823143803870779]\n",
      "Average AUC 0.644370335948 [0.68606189005427454, 0.54464419831126576, 0.70240491947721106]\n",
      "60 247986.035643 -4.73349030134 4.31956133433 [ 1.41336016  1.03530614  1.52170288  0.02375125]\n",
      "Average AUC 0.634079114663 [0.68244178212597395, 0.52462389867677606, 0.69517166318681511]\n",
      "Average AUC 0.647939636721 [0.68953995312877991, 0.54612286112606678, 0.70815609590925443]\n",
      "65 239578.891477 -4.61627184587 4.2063839005 [ 1.40929415  1.03960893  1.57894048  0.02226786]\n",
      "Average AUC 0.638196825461 [0.68569083931410946, 0.52695499983086236, 0.70194463723663636]\n",
      "Average AUC 0.650065477273 [0.69093253596961501, 0.54871085093962035, 0.71055304491061888]\n",
      "70 231599.409525 -4.50373919076 4.10271571475 [ 1.40040561  1.04364504  1.63469186  0.0149557 ]\n",
      "Average AUC 0.641469567243 [0.6889259937400436, 0.52797888117189107, 0.70750382681759671]\n",
      "Average AUC 0.65197315735 [0.69320091832959307, 0.54996936843990518, 0.71274918528187936]\n",
      "75 223884.058602 -4.39584708471 4.00373792946 [ 1.39146806  1.04793181  1.69151224  0.00846517]\n",
      "Average AUC 0.644243649337 [0.69142655394800678, 0.52929724539400747, 0.71200714866852888]\n",
      "Average AUC 0.652845346068 [0.69602035953505814, 0.55089879555294496, 0.71161688311649374]\n",
      "80 217045.847778 -4.29484911766 3.91194424475 [  1.38224128e+00   1.05215857e+00   1.73899110e+00   7.97067203e-04]\n",
      "Average AUC 0.647452298711 [0.69423243623534803, 0.53146234950291849, 0.71666211039615635]\n",
      "Average AUC 0.654858159091 [0.69893982498267682, 0.55217189209860018, 0.71346276019227228]\n",
      "85 210716.666704 -4.19955197075 3.82406972705 [ 1.37479684  1.05624648  1.7810651  -0.00487287]\n",
      "Average AUC 0.649991312167 [0.69644658005746296, 0.53321056555005131, 0.7203167908939816]\n",
      "Average AUC 0.655275106191 [0.6985801125009683, 0.55042276291552961, 0.71682244315737809]\n",
      "90 205053.967231 -4.10840383632 3.74276642168 [ 1.36493083  1.0604162   1.81884285 -0.01379644]\n",
      "Average AUC 0.652937145405 [0.69911550351798923, 0.5361039266989811, 0.7235920059994092]\n",
      "Average AUC 0.656324088213 [0.70144521906529678, 0.55252984138621231, 0.71499720418848356]\n",
      "95 199433.912933 -4.02236323473 3.66187403058 [ 1.359762    1.06490088  1.85339566 -0.01722891]\n",
      "Average AUC 0.654961588352 [0.70049303458433021, 0.53851588188974031, 0.72587584858290088]\n",
      "Average AUC 0.655185320315 [0.70207368867410502, 0.55225060683763105, 0.71123166543257677]\n",
      "100 194228.638088 -3.93855493325 3.58680725838 [ 1.35100039  1.06946636  1.88747955 -0.02480996]\n",
      "Average AUC 0.657146636505 [0.70234987283327954, 0.54097188551295305, 0.72811815116854239]\n",
      "Average AUC 0.658083976404 [0.70168625662901296, 0.55149614383385248, 0.72106952874793873]\n",
      "105 189476.930247 -3.85868905436 3.51339402947 [ 1.34452814  1.07412274  1.92022292 -0.02921669]\n",
      "Average AUC 0.659561463481 [0.70388011651592097, 0.54459603557881997, 0.73020823834858217]\n",
      "Average AUC 0.657150888092 [0.70126679837346617, 0.55237762266303791, 0.71780824324057779]\n",
      "110 184588.622004 -3.78008411162 3.44480961477 [ 1.33448847  1.07889164  1.95402957 -0.0381913 ]\n",
      "Average AUC 0.66135704961 [0.70546553571153692, 0.54664092049913393, 0.73196469262050234]\n",
      "Average AUC 0.659716553699 [0.70301234575598814, 0.55333184452975193, 0.7228054708099233]\n",
      "115 179987.699581 -3.70627539811 3.37772563817 [ 1.32774501  1.08375     1.98356079 -0.04337466]\n",
      "Average AUC 0.663712861892 [0.70677261312639195, 0.5498144033912209, 0.734551569158581]\n",
      "Average AUC 0.661162448579 [0.70304306249358084, 0.55509488174163257, 0.72534940150089544]\n",
      "120 175734.805681 -3.63352612545 3.31531958606 [ 1.31738347  1.08853943  2.0134609  -0.05196463]\n",
      "Average AUC 0.665263059352 [0.70779353776919174, 0.55205993609847037, 0.73593570418869336]\n",
      "Average AUC 0.660484018917 [0.70226377714163313, 0.55606315344993484, 0.72312512615923352]\n",
      "125 171812.352381 -3.56446182599 3.25313821529 [ 1.3104826   1.0931546   2.04221455 -0.05640654]\n",
      "Average AUC 0.666889808499 [0.70856600068156783, 0.55502054763390918, 0.73708287718171162]\n",
      "Average AUC 0.662246977571 [0.70247807796295403, 0.5567122530183467, 0.72755060173045949]\n",
      "130 167950.530542 -3.49657868547 3.19607593373 [ 1.29964414  1.09740811  2.06989695 -0.06540234]\n",
      "Average AUC 0.668484735487 [0.70955874730221369, 0.55716155740591633, 0.73873390175206]\n",
      "Average AUC 0.661873058461 [0.70379886042966588, 0.55483943888073339, 0.72698087607369855]\n",
      "135 164642.160059 -3.434262639 3.13840258784 [ 1.29498418  1.10141138  2.09361673 -0.06698645]\n",
      "Average AUC 0.670361917306 [0.71018871549812657, 0.56096648417552708, 0.73993055224576465]\n",
      "Average AUC 0.660418695439 [0.70376644452925685, 0.55574913326451147, 0.72174050852415272]\n",
      "140 161178.397078 -3.37091522407 3.08718727256 [ 1.28283513  1.10532793  2.11740891 -0.07725464]\n",
      "Average AUC 0.671693570022 [0.71097523017180442, 0.56279745316702179, 0.74130802672780216]\n",
      "Average AUC 0.662414842893 [0.70290308356961817, 0.5566357623187399, 0.7277056827904087]\n",
      "145 157726.376115 -3.31253923454 3.03289446634 [ 1.27873529  1.10934589  2.13994609 -0.07882345]\n",
      "Average AUC 0.672955355144 [0.71118537047978714, 0.56500473793033179, 0.74267595702213907]\n",
      "Average AUC 0.662226648747 [0.70461992570240084, 0.55500039292516101, 0.72705962761241405]\n",
      "150 154817.878053 -3.25384128111 2.98421216384 [ 1.26870327  1.1133535   2.16182501 -0.08662896]\n",
      "Average AUC 0.673744951238 [0.71158792020282124, 0.5662861270646643, 0.74336080644549196]\n",
      "Average AUC 0.66333238492 [0.70629249504483438, 0.55644579718462206, 0.72725886253066407]\n",
      "155 152137.340392 -3.20019073423 2.93490936037 [ 1.26433943  1.11751604  2.18068031 -0.08795293]\n",
      "Average AUC 0.67535990363 [0.71210696429932274, 0.56938677698916806, 0.74458596960044332]\n",
      "Average AUC 0.660928953417 [0.70421149911100844, 0.55635155221695209, 0.72222380892344384]\n",
      "160 149461.602125 -3.14555873826 2.89090053554 [ 1.25370041  1.12162523  2.1993306  -0.09597023]\n",
      "Average AUC 0.676565901777 [0.71255609916412754, 0.57108969250078123, 0.74605191366658741]\n",
      "Average AUC 0.6631508776 [0.70534501549699524, 0.55588729176955298, 0.72822032553473681]\n",
      "165 146674.889475 -3.09557273764 2.84433862794 [ 1.25026071  1.12595635  2.21682698 -0.09637242]\n",
      "Average AUC 0.677610804918 [0.71299534278096899, 0.57267854211483249, 0.74715852985697084]\n",
      "Average AUC 0.661780023382 [0.70294532481454275, 0.55832853648728642, 0.72406620884541173]\n",
      "170 144358.813001 -3.04445537782 2.80294107216 [ 1.24052554  1.13030495  2.23412441 -0.1030128 ]\n",
      "Average AUC 0.678074115378 [0.71304502251943747, 0.57349940289902679, 0.74767792071477812]\n",
      "Average AUC 0.662826048857 [0.70389956662924003, 0.55814389279119991, 0.7264346871511792]\n",
      "175 142272.098241 -2.99803042808 2.76053216941 [ 1.23649435  1.13474775  2.24933006 -0.10352514]\n",
      "Average AUC 0.679008068771 [0.71345334882297406, 0.57550919088615626, 0.74806166660341844]\n",
      "Average AUC 0.664964740632 [0.7071063166690027, 0.5601153273395183, 0.72767257788809547]\n",
      "180 140185.003971 -2.95043722925 2.72297515785 [ 1.22644322  1.13923447  2.26391265 -0.11032309]\n",
      "Average AUC 0.679907963913 [0.7136673401846253, 0.57678704161872996, 0.74926950993533747]\n",
      "Average AUC 0.665566734149 [0.70875712641206301, 0.56089499497048867, 0.72704808106372609]\n",
      "185 137889.674851 -2.90749594495 2.68279038624 [ 1.22367198  1.14397454  2.27727778 -0.10992233]\n",
      "Average AUC 0.680675576487 [0.71427909037516357, 0.57777361582254283, 0.74997402326299833]\n",
      "Average AUC 0.663316687697 [0.70695651813125915, 0.55709626991578887, 0.72589727504448509]\n",
      "190 136111.165685 -2.86354133417 2.64732936312 [ 1.21516386  1.14868266  2.28989995 -0.11503162]\n",
      "Average AUC 0.681224613403 [0.71417310616899954, 0.57864567793736976, 0.75085505610237802]\n",
      "Average AUC 0.663763223306 [0.70858431324406346, 0.55963467195141781, 0.72307068472172786]\n",
      "195 134627.318029 -2.82396267637 2.61096097157 [ 1.21193925  1.15352733  2.30064108 -0.11471793]\n",
      "Average AUC 0.681859981886 [0.71441012935311043, 0.58025381408925858, 0.75091600221554644]\n",
      "Average AUC 0.668102296055 [0.71186754566813826, 0.56753347594395254, 0.72490586655199263]\n",
      "200 132956.371627 -2.78283658757 2.57908889521 [ 1.20267108  1.15844184  2.31076983 -0.12053588]\n",
      "Average AUC 0.682713116105 [0.71444975165231117, 0.58132318966130891, 0.75236640700121327]\n",
      "Average AUC 0.673143460466 [0.72120625339137712, 0.57358562160933424, 0.7246385063969738]\n",
      "205 131140.042381 -2.74594835403 2.54432680096 [ 1.20053095  1.16355886  2.32029047 -0.11951656]\n",
      "Average AUC 0.683346778497 [0.71488066851174159, 0.58218963806542745, 0.75297002891253384]\n",
      "Average AUC 0.671084398813 [0.71900567708348795, 0.57084062083835707, 0.72340689851728768]\n",
      "210 129693.321521 -2.70778720596 2.51398875123 [ 1.19269403  1.16865171  2.32928684 -0.12378514]\n",
      "Average AUC 0.683669548691 [0.71457522608693669, 0.58270127089844759, 0.75373214908668651]\n",
      "Average AUC 0.670698508767 [0.71962328408481357, 0.56928644271915563, 0.72318579949568096]\n",
      "215 128670.697665 -2.67371642929 2.48192981447 [ 1.19066853  1.1738768   2.33728151 -0.12237863]\n",
      "Average AUC 0.683883552295 [0.7146842189287792, 0.58363061845797759, 0.75333581949830786]\n",
      "Average AUC 0.672068126551 [0.72083644622062581, 0.57257740539202617, 0.72279052804117716]\n",
      "220 127346.265838 -2.63735739615 2.45528006135 [ 1.18094575  1.17921707  2.34418811 -0.12851719]\n",
      "Average AUC 0.68491380847 [0.71479045528726681, 0.58493767570516753, 0.75501329441798704]\n",
      "Average AUC 0.674151139538 [0.72325924322508839, 0.57520712275085806, 0.72398705263793373]\n",
      "225 125829.738741 -2.60564803438 2.42420232694 [ 1.18030078  1.18463197  2.35114778 -0.12631371]\n",
      "Average AUC 0.68518783966 [0.71498412546393597, 0.58515310315067182, 0.75542629036428521]\n",
      "Average AUC 0.672972835875 [0.72334740484656712, 0.57385483241568935, 0.72171627036405628]\n",
      "230 124646.882582 -2.5718708334 2.39830041667 [ 1.17241229  1.19001175  2.35755132 -0.13051281]\n",
      "Average AUC 0.685301055559 [0.71441839880317515, 0.58568104445318681, 0.75580372342023161]\n",
      "Average AUC 0.673369524242 [0.72087614301937664, 0.57473387275685917, 0.72449855695119325]\n",
      "235 123884.22136 -2.54202626409 2.37054358229 [ 1.17031149  1.19535246  2.36314187 -0.12940226]\n",
      "Average AUC 0.684825289161 [0.71428184685851837, 0.58558268518552459, 0.75461133543749104]\n",
      "Average AUC 0.671762846752 [0.71795510161973597, 0.57527423997170946, 0.72205919866352597]\n",
      "240 122807.482116 -2.50991661123 2.34717915484 [ 1.16155335  1.20080682  2.36815485 -0.13445357]\n",
      "Average AUC 0.685621608536 [0.71415112880171061, 0.5865230560944249, 0.75619064071295083]\n",
      "Average AUC 0.673572623232 [0.72241055008072363, 0.57601743577731623, 0.72228988383848292]\n",
      "245 121438.879505 -2.48206008516 2.31975129114 [ 1.16111189  1.2064099   2.37324302 -0.13214444]\n",
      "Average AUC 0.685860483071 [0.71440396881338808, 0.58665296697581626, 0.75652451342478122]\n",
      "Average AUC 0.673103106929 [0.72387096189658617, 0.57369139664764268, 0.7217469622415269]\n",
      "250 120847.985711 -2.45225167356 2.29781979283 [ 1.15322232  1.21198439  2.3774086  -0.13618262]\n",
      "Average AUC 0.685875918633 [0.71369386202447216, 0.58760814175522302, 0.75632575211886066]\n",
      "Average AUC 0.67373712592 [0.72230529367785701, 0.57749414261343235, 0.72141194146942977]\n",
      "255 120014.647925 -2.42619604204 2.27209708577 [ 1.15287686  1.21765045  2.38172255 -0.13373669]\n",
      "Average AUC 0.685380796636 [0.71340760036845863, 0.58703627999763963, 0.75569850954199957]\n",
      "Average AUC 0.67258507451 [0.72330725818514807, 0.57402093668516019, 0.72042702865996067]\n",
      "260 119154.027145 -2.3971362942 2.25258449831 [ 1.14331729  1.22336978  2.38490532 -0.13936804]\n",
      "Average AUC 0.686163381247 [0.71330107747323979, 0.58812603164472588, 0.75706303462363911]\n",
      "Average AUC 0.673976987092 [0.72019784180763247, 0.57529013510883853, 0.72644298435958232]\n",
      "265 117928.010511 -2.37278329527 2.22788580499 [ 1.14365069  1.22922283  2.38836537 -0.13667027]\n",
      "Average AUC 0.686093957782 [0.71382823628997094, 0.58771563238226299, 0.75673800467365437]\n",
      "Average AUC 0.674491859061 [0.72342297604407368, 0.5748745873507568, 0.72517801378859348]\n",
      "270 117280.356244 -2.34590163687 2.20785000527 [ 1.13679265  1.23499701  2.3916326  -0.1399197 ]\n",
      "Average AUC 0.685942475727 [0.7127016827465541, 0.58824370166216333, 0.75688204277270876]\n",
      "Average AUC 0.672776685592 [0.72073898648221713, 0.57663959091786687, 0.7209514793760714]\n",
      "275 116428.09471 -2.3223535343 2.18548803578 [ 1.13559445  1.24077533  2.39441659 -0.13879718]\n",
      "Average AUC 0.686044946506 [0.71318392979602518, 0.58789708356141557, 0.75705382616113404]\n",
      "Average AUC 0.674670342835 [0.72385989871339151, 0.57467630195717545, 0.72547482783442441]\n",
      "280 116047.467078 -2.29654097553 2.1683008678 [ 1.1269571   1.24665755  2.39632834 -0.14360884]\n",
      "Average AUC 0.686372341721 [0.71250213283615937, 0.58918468824605197, 0.75743020408075168]\n",
      "Average AUC 0.672099206999 [0.7226877915604365, 0.57329546055913394, 0.7203143688764998]\n",
      "285 114888.333014 -2.27503950841 2.14591618614 [ 1.12782847  1.25272181  2.39860133 -0.14088169]\n",
      "Average AUC 0.686475363838 [0.71288925542158155, 0.58926652113677958, 0.75727031495639574]\n",
      "Average AUC 0.675548825199 [0.7250399343377012, 0.57621829455399498, 0.72538824670454249]\n",
      "290 114379.911871 -2.2498888817 2.12833717455 [ 1.1202451   1.25877931  2.40091498 -0.14515353]\n",
      "Average AUC 0.6864448183 [0.71207384065318735, 0.58949433125901585, 0.7577662829867241]\n",
      "Average AUC 0.67419431841 [0.72187831669848157, 0.57554627665708402, 0.72515836187447125]\n",
      "295 114049.1022 -2.22975537868 2.10765758676 [ 1.12077954  1.26492903  2.40249325 -0.14270861]\n",
      "Average AUC 0.685130452305 [0.71159732433834166, 0.58860613707595477, 0.75518789550001741]\n",
      "Average AUC 0.673739491502 [0.72315842814155629, 0.57570607198734836, 0.72235397437781268]\n",
      "300 113088.335172 -2.20557551423 2.09121937548 [ 1.11302633  1.2710774   2.40427918 -0.14731805]\n",
      "Average AUC 0.686395075272 [0.7116283734585428, 0.58969384454372564, 0.75786300781358418]\n",
      "Average AUC 0.675875388277 [0.72351598013631113, 0.57730237196052847, 0.72680781273296569]\n",
      "305 112339.017356 -2.18595053954 2.07112000538 [ 1.11348927  1.27731045  2.40594455 -0.14531713]\n",
      "Average AUC 0.686423095906 [0.71215767557002385, 0.58962864525422853, 0.75748296689228001]\n",
      "Average AUC 0.674111454903 [0.72099643973526795, 0.57488402654762882, 0.72645389842598229]\n",
      "310 112123.818548 -2.16369188821 2.0550428552 [ 1.10729641  1.28357391  2.40742528 -0.14842446]\n",
      "Average AUC 0.685342937002 [0.710181913116126, 0.59025478325853797, 0.75559211463049036]\n",
      "Average AUC 0.672741820359 [0.71994041147751986, 0.57569533918123117, 0.72258971041843412]\n",
      "315 111234.409966 -2.14374295097 2.03681838905 [ 1.10556067  1.28984889  2.4088923  -0.14829323]\n",
      "Average AUC 0.68521246351 [0.71111597128347215, 0.58907575873814022, 0.75544566050904693]\n",
      "Average AUC 0.672077314353 [0.72096857403815151, 0.57434173621315188, 0.72092163280668242]\n",
      "320 110619.816208 -2.12270826185 2.02048304367 [ 1.10085014  1.29614948  2.41030295 -0.15052817]\n",
      "Average AUC 0.686161146998 [0.71052403224253424, 0.5905425317620846, 0.75741687698950899]\n",
      "Average AUC 0.675733717427 [0.72337935082673699, 0.57772642156760678, 0.72609537988774675]\n",
      "325 110385.550395 -2.10524934207 2.0024292269 [ 1.10143394  1.30253297  2.4111863  -0.1486349 ]\n",
      "Average AUC 0.685375685678 [0.71066551834970348, 0.5899164975232225, 0.75554504116200727]\n",
      "Average AUC 0.671598599519 [0.71769931601046111, 0.5749164048260893, 0.7221800777191838]\n",
      "330 109830.546996 -2.08372818387 1.98860198584 [ 1.09372901  1.30906339  2.41226342 -0.15310877]\n",
      "Average AUC 0.685463020898 [0.70956733767341729, 0.59075080630940957, 0.75607091871019882]\n",
      "Average AUC 0.672891930851 [0.71784795120907563, 0.57679660187529069, 0.72403123946924486]\n",
      "335 109301.528458 -2.06666557485 1.97035645885 [ 1.094901    1.31565817  2.41335139 -0.15102366]\n",
      "Average AUC 0.685026335243 [0.70991534226428599, 0.59028905352699113, 0.75487460993678235]\n",
      "Average AUC 0.672875708755 [0.72249400103834027, 0.57473853355487481, 0.72139459167093367]\n",
      "340 108871.5211 -2.0458438149 1.9572376764 [ 1.08718718  1.32235183  2.41405595 -0.15560745]\n",
      "Average AUC 0.685110258192 [0.70886706482511874, 0.59081094876276652, 0.75565276098902012]\n",
      "Average AUC 0.673450563643 [0.72169442888581825, 0.57543961961247203, 0.72321764243096454]\n",
      "345 108081.321343 -2.02979871644 1.93930738413 [ 1.0890616   1.32907687  2.41471736 -0.15336281]\n",
      "Average AUC 0.68519890069 [0.70981071624222802, 0.59034923402767869, 0.75543675180118053]\n",
      "Average AUC 0.675048496255 [0.72443957398223091, 0.57450996421544775, 0.72619595056662334]\n",
      "350 107463.974952 -2.00971454328 1.92596721452 [ 1.08230691  1.33588137  2.41557316 -0.1572221 ]\n",
      "Average AUC 0.685642156964 [0.70945524450414243, 0.59134359409890047, 0.75612763228786706]\n",
      "Average AUC 0.67485858837 [0.72192639756198962, 0.57508225832906223, 0.72756710921842027]\n",
      "355 107203.18139 -1.99410432524 1.9096337079 [ 1.08301958  1.34265972  2.41610699 -0.15568577]\n",
      "Average AUC 0.684662102515 [0.70912408254233816, 0.59088041627100329, 0.75398180873028198]\n",
      "Average AUC 0.671552296196 [0.72097691512239903, 0.57323754041577712, 0.72044243305085054]\n",
      "360 106798.890055 -1.9748975615 1.89660624117 [ 1.07682975  1.34954945  2.41665429 -0.15937497]\n",
      "Average AUC 0.68513833169 [0.70804190780786125, 0.59175888071393956, 0.75561420654737277]\n",
      "Average AUC 0.674364762601 [0.72455335771822038, 0.57599277764814782, 0.72254815243530557]\n",
      "365 106180.021074 -1.95935864898 1.88063158452 [ 1.07725502  1.35642457  2.41722684 -0.15826073]\n",
      "Average AUC 0.685036831099 [0.70873313182618591, 0.59129126864258674, 0.75508609282957528]\n",
      "Average AUC 0.675847663198 [0.72288891742285322, 0.57611298818962431, 0.72854108398111805]\n",
      "370 106210.482509 -1.94126122783 1.87001090704 [ 1.06976788  1.36341527  2.41703595 -0.16251313]\n",
      "Average AUC 0.685118126123 [0.70745850756151507, 0.59335356886383539, 0.7545423019441666]\n",
      "Average AUC 0.673365422498 [0.71917084545149701, 0.57648133650449762, 0.72444408553822359]\n",
      "375 105461.815061 -1.92644741445 1.8528498094 [ 1.07210484  1.37051646  2.41794292 -0.16026444]\n",
      "Average AUC 0.684276425705 [0.70873314901838991, 0.59055998856919834, 0.75353613952835041]\n",
      "Average AUC 0.672809401798 [0.7206149275390441, 0.57175738164910828, 0.72605589620671884]\n",
      "380 105191.003155 -1.90892442859 1.84083206013 [ 1.06658935  1.3776385   2.41823506 -0.16326157]\n",
      "Average AUC 0.683874561782 [0.70590467617515495, 0.59250191049483036, 0.75321709867604969]\n",
      "Average AUC 0.671014835877 [0.71676045835286606, 0.57383591597461447, 0.72244813330496449]\n",
      "385 104488.714259 -1.89336019288 1.82637819776 [ 1.06546878  1.38475261  2.41873263 -0.163433  ]\n",
      "Average AUC 0.683505016762 [0.70694158383682515, 0.5915561956653852, 0.75201727078317315]\n",
      "Average AUC 0.671639135265 [0.71993882406402865, 0.57369410492582185, 0.72128447680435648]\n",
      "390 104181.350263 -1.87690584521 1.81534185873 [ 1.06004065  1.39186638  2.41862855 -0.16654177]\n",
      "Average AUC 0.685072670266 [0.7071900799516565, 0.59315308710161596, 0.75487484374540059]\n",
      "Average AUC 0.673987136941 [0.72380728483879475, 0.57325220420292955, 0.72490192178094548]\n",
      "395 103865.3823 -1.86337515758 1.79980241192 [ 1.06203935  1.39915343  2.41906187 -0.16474272]\n",
      "Average AUC 0.68393662561 [0.70767044732017037, 0.59151130673280727, 0.75262812277638258]\n",
      "Average AUC 0.67434321156 [0.722841154615117, 0.57383375246503465, 0.72635472760126918]\n",
      "400 103686.56124 -1.84681676447 1.78911852947 [ 1.05615484  1.40648349  2.4190945  -0.16796729]\n",
      "Average AUC 0.682922977809 [0.70450822795381529, 0.59309838887540312, 0.75116231659737243]\n",
      "Average AUC 0.672019685509 [0.71878080592215032, 0.57463798656569509, 0.72264026403827408]\n",
      "405 102996.130428 -1.8331077922 1.77486997992 [ 1.05668448  1.41386414  2.41922867 -0.16728998]\n",
      "Average AUC 0.683798484202 [0.70627597047154167, 0.59346420704278224, 0.75165527509112695]\n",
      "Average AUC 0.669247638779 [0.71621621908158351, 0.57015068437809113, 0.72137601287841846]\n",
      "410 102704.391551 -1.81674218678 1.76423965002 [ 1.05093933  1.42127924  2.41927095 -0.17071042]\n",
      "Average AUC 0.684018541636 [0.70562216815032131, 0.59394947999329539, 0.75248397676565826]\n",
      "Average AUC 0.675142551344 [0.72460729252714851, 0.57796182213232605, 0.72285853937118305]\n",
      "415 102295.002579 -1.80376459443 1.74996387486 [ 1.0522277   1.42875668  2.41948408 -0.1695882 ]\n",
      "Average AUC 0.683441885124 [0.7065509998876891, 0.59269278703546191, 0.75108186844740099]\n",
      "Average AUC 0.674121125068 [0.72261324902979518, 0.57331075385666774, 0.72643937231618427]\n",
      "420 102241.131354 -1.78853292366 1.74071492171 [ 1.04623523  1.43627896  2.41918388 -0.17280138]\n",
      "Average AUC 0.682539411816 [0.70320732827088639, 0.59451267387716622, 0.74989823330011451]\n",
      "Average AUC 0.669687456055 [0.71425257426605127, 0.57135815100764209, 0.72345164289222708]\n",
      "425 101506.206218 -1.77489835424 1.72620918345 [ 1.0470967   1.44387635  2.4197146  -0.17210779]\n",
      "Average AUC 0.682709763557 [0.70506532985896475, 0.59354344233847467, 0.74952051847480772]\n",
      "Average AUC 0.670530431901 [0.72136599761906317, 0.57099145775165594, 0.7192338403323344]\n",
      "430 101167.887746 -1.76015291024 1.71624418798 [ 1.04230661  1.45149143  2.41947758 -0.17494491]\n",
      "Average AUC 0.684007893009 [0.70514306154342499, 0.5948697134876888, 0.75201090399464421]\n",
      "Average AUC 0.67324807992 [0.72484050477273354, 0.57203325938546357, 0.72287047560090167]\n",
      "435 100831.310126 -1.74757766189 1.70310776998 [ 1.04285819  1.45918739  2.41963364 -0.17432613]\n",
      "Average AUC 0.682454114827 [0.70482226074982379, 0.59402339558038064, 0.74851668815008177]\n",
      "Average AUC 0.673078266669 [0.72441694331119488, 0.57576756512094662, 0.71905029157433475]\n",
      "440 100560.789655 -1.73286880327 1.69348166996 [ 1.03776591  1.46693264  2.41938888 -0.17736853]\n",
      "Average AUC 0.683666844141 [0.70412173574920167, 0.59569838089238147, 0.75118041578246542]\n",
      "Average AUC 0.673600961836 [0.72617411835427192, 0.57384435902319086, 0.72078440813056877]\n",
      "445 100096.672743 -1.72089214477 1.68019014905 [ 1.03907129  1.47473844  2.41939579 -0.1765612 ]\n",
      "Average AUC 0.683129526558 [0.70534315014287463, 0.59442880372481977, 0.74961662580711175]\n",
      "Average AUC 0.673725152477 [0.72615106360887349, 0.57126578419457164, 0.72375860962767535]\n"
     ]
    }
   ],
   "source": [
    "def total_loss():\n",
    "    loss = 0\n",
    "    for item in item_data:\n",
    "        for r in item_data[item]:\n",
    "            s = true_size_cust[user_index[r['user_id']]]\n",
    "            t = true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]\n",
    "            b_i = bias_i[p_item_index[r['item_id']]]\n",
    "            b_u = bias_u[user_index[r['user_id']]]\n",
    "            \n",
    "            if 'small' in r['fit']:\n",
    "                loss += max(0, 1 - f(alpha,b_i,b_u,s,t) + b_2)\n",
    "            elif 'fit' in r['fit']:\n",
    "                loss += max(0, 1 + f(alpha,b_i,b_u,s,t) - b_2)\n",
    "                loss += max(0, 1 - f(alpha,b_i,b_u,s,t) + b_1)\n",
    "            elif 'large' in r['fit']:\n",
    "                loss += max(0, 1 + f(alpha,b_i,b_u,s,t) - b_1)\n",
    "    return loss\n",
    "\n",
    "for iterr in range(0,450):\n",
    "    learning_rate1 = 0.00025\n",
    "    learning_rate2 = 0.00001/np.sqrt(iterr+1)\n",
    "    \n",
    "    grad_b1 = 0\n",
    "    grad_b2 = 0\n",
    "    grad_s = np.zeros((len(user_index), K))\n",
    "    grad_t = np.zeros((len(item_index), K))\n",
    "    grad_bu = np.zeros(len(user_index))\n",
    "    grad_bi = np.zeros(len(p_item_index))\n",
    "    grad_bs = np.zeros(len(sizes))\n",
    "    grad_w = np.zeros((K+3))\n",
    "    for r in train_data:\n",
    "        s = true_size_cust[user_index[r['user_id']]]\n",
    "        t = true_size_item[item_index[r['item_id'] + '|' + str(r['size'])]]\n",
    "        b_i = bias_i[p_item_index[r['item_id']]]\n",
    "        b_u = bias_u[user_index[r['user_id']]]\n",
    "        \n",
    "        if 'small' in r['fit']:\n",
    "            A = 1 - f(alpha,b_i,b_u,s,t) + b_2\n",
    "            if A>0:\n",
    "                grad_s[user_index[r['user_id']]] += -1*np.multiply(w[3:],t)\n",
    "                grad_t[item_index[r['item_id'] + '|' + str(r['size'])]] += -1*np.multiply(w[3:],s)\n",
    "                \n",
    "                grad_bu[user_index[r['user_id']]] += -1*w[1]\n",
    "                grad_bi[p_item_index[r['item_id']]] += -1*w[2]\n",
    "                grad_w += -1*np.concatenate(([alpha, b_u, b_i], np.multiply(s, t)))\n",
    "                grad_b2 += 1\n",
    "        elif 'fit' in r['fit']:\n",
    "            B = 1 + f(alpha,b_i,b_u,s,t) - b_2\n",
    "            C = 1 - f(alpha,b_i,b_u,s,t) + b_1\n",
    "            if B>0:\n",
    "                grad_s[user_index[r['user_id']]] += np.multiply(w[3:],t)\n",
    "                grad_t[item_index[r['item_id'] + '|' + str(r['size'])]] += np.multiply(w[3:],s)\n",
    "                \n",
    "                grad_bu[user_index[r['user_id']]] += w[1]\n",
    "                grad_bi[p_item_index[r['item_id']]] += w[2]\n",
    "                grad_w += np.concatenate(([alpha, b_u, b_i], np.multiply(s, t)))\n",
    "                grad_b2 += -1\n",
    "            if C>0:\n",
    "                grad_s[user_index[r['user_id']]] += -1*np.multiply(w[3:],t)\n",
    "                grad_t[item_index[r['item_id'] + '|' + str(r['size'])]] += -1*np.multiply(w[3:],s)\n",
    "                \n",
    "                grad_bu[user_index[r['user_id']]] += -1*w[1]\n",
    "                grad_bi[p_item_index[r['item_id']]] += -1*w[2]\n",
    "                grad_w += -1*np.concatenate(([alpha, b_u, b_i], np.multiply(s, t)))\n",
    "                grad_b1 += 1\n",
    "        elif 'large' in r['fit']:\n",
    "            D = 1 + f(alpha,b_i,b_u,s,t) - b_1\n",
    "            if D>0:\n",
    "                grad_s[user_index[r['user_id']]] += np.multiply(w[3:],t)\n",
    "                grad_t[item_index[r['item_id'] + '|' + str(r['size'])]] += np.multiply(w[3:],s)\n",
    "                \n",
    "                grad_bu[user_index[r['user_id']]] += w[1]\n",
    "                grad_bi[p_item_index[r['item_id']]] += w[2]\n",
    "                grad_w += np.concatenate(([alpha, b_u, b_i], np.multiply(s, t)))\n",
    "                grad_b1 += -1\n",
    "\n",
    "    for i in range(len(user_index)):\n",
    "        true_size_cust[i] -= learning_rate1*(grad_s[i] + 2*lamda*true_size_cust[i])\n",
    "        bias_u[i] -= learning_rate1*(grad_bu[i] + 2*lamda*bias_u[i])\n",
    "        \n",
    "    for i in range(len(item_index)):\n",
    "        ## constraint update\n",
    "        temp = true_size_item[i] - learning_rate1*(grad_t[i] + 2*lamda*true_size_item[i])\n",
    "        if product_smaller[i] != -1:\n",
    "            temp = np.maximum(temp, true_size_item[product_smaller[i]])\n",
    "        if product_larger[i] != -1:\n",
    "            temp = np.minimum(temp, true_size_item[product_larger[i]])\n",
    "        true_size_item[i] = temp\n",
    "        \n",
    "    for i in range(len(p_item_index)):\n",
    "        bias_i[i] -= learning_rate1*(grad_bi[i] + 2*lamda*bias_i[i])        \n",
    "    \n",
    "    b_1 -= learning_rate2*(grad_b1 + 2*lamda*b_1)\n",
    "    b_2 -= learning_rate2*(grad_b2 + 2*lamda*b_2)\n",
    "    w -= learning_rate2*(grad_w + 2*lamda*w)\n",
    "    if iterr%5 == 0:    \n",
    "        print(iterr, total_loss(), b_1, b_2,w[:4])\n",
    "        calc_auc()\n",
    "        auc = calc_metric_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC 0.719119530864 [0.75434250427762084, 0.64011046108591652, 0.76290562722788891]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.71911953086380864"
      ]
     },
     "execution_count": 1212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metric_auc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
